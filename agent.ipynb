{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitors research agent\n",
    "Steps for competitors research:\n",
    "1. Find list of competitors  \n",
    "2. Go to their website  \n",
    "3. Collect information including:  \n",
    "\t- standout features\n",
    "\t- product and pricing tiers\n",
    "\t- unique service proposition\n",
    "\t- marketing messages  \n",
    "4. Analyze competitors  \n",
    "\t- identify common patterns  \n",
    "\t- spot potential gaps  \n",
    "\t- compare pricing strategies  \n",
    "\t- compare messaging themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimiter:\n",
    "    def __init__(self, calls_per_minute: int):\n",
    "        self.calls_per_minute = calls_per_minute\n",
    "        self.calls = []\n",
    "        \n",
    "    async def wait_if_needed(self):\n",
    "        now = datetime.now()\n",
    "        self.calls = [call for call in self.calls \n",
    "                     if (now - call).total_seconds() < 60]\n",
    "        \n",
    "        if len(self.calls) >= self.calls_per_minute:\n",
    "            sleep_time = 60 - (now - self.calls[0]).total_seconds()\n",
    "            await asyncio.sleep(sleep_time)\n",
    "            \n",
    "        self.calls.append(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.gemini_client = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "        self.rate_limiter = RateLimiter(calls_per_minute=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.system_prompt = \"\"\n",
    "        self.role = \"\"\n",
    "        self.goal = \"\"\n",
    "        self.backstory = \"\"\n",
    "\n",
    "    async def execute(self, input_data: Any) -> Any:\n",
    "        await self.config.rate_limiter.wait_if_needed()\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Role: {self.role}\n",
    "        Goal: {self.goal}\n",
    "        Backstory: {self.backstory}\n",
    "        System Instructions: {self.system_prompt}\n",
    "        \n",
    "        Input Data:\n",
    "        {json.dumps(input_data, indent=2)}\n",
    "        \n",
    "        Please provide your analysis based on the above information.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.config.gemini_client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash-exp\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            \n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in agent execution: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketIntelligenceScout(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Expert market researcher specializing in competitor identification\"\n",
    "        self.goal = \"Identify and categorize the most relevant competitors\"\n",
    "        self.backstory = \"Former market research director with 15 years of experience\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        1. Search for top competitors in the given market\n",
    "        2. Return results in JSON format with the following structure:\n",
    "        {\n",
    "            \"competitors\": [\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"website\": \"\",\n",
    "                    \"market_segment\": \"\",\n",
    "                    \"threat_level\": \"\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitalProductAnalyst(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Product analysis specialist\"\n",
    "        self.goal = \"Analyze product features and capabilities\"\n",
    "        self.backstory = \"Previously a product manager at major tech companies\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Analyze each competitor's product features and capabilities.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"competitor_name\": {\n",
    "                \"key_features\": [],\n",
    "                \"unique_capabilities\": [],\n",
    "                \"user_experience\": \"\",\n",
    "                \"product_maturity\": \"\"\n",
    "            }\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketingMessageDecoder(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Marketing communications analyst\"\n",
    "        self.goal = \"Decode and analyze competitors' marketing strategies\"\n",
    "        self.backstory = \"Former copywriter turned marketing strategist\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Analyze marketing messages and positioning.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"competitor_name\": {\n",
    "                \"value_propositions\": [],\n",
    "                \"messaging_tone\": \"\",\n",
    "                \"target_audience\": \"\",\n",
    "                \"unique_selling_points\": []\n",
    "            }\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechnicalFeatureComparator(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Technical analyst specializing in feature comparison\"\n",
    "        self.goal = \"Provide detailed technical comparison of competitor products\"\n",
    "        self.backstory = \"Senior solutions architect with cross-industry experience\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Compare technical features across competitors.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"competitor_name\": {\n",
    "                \"tech_stack\": [],\n",
    "                \"api_capabilities\": [],\n",
    "                \"scalability_features\": [],\n",
    "                \"technical_advantages\": [],\n",
    "                \"technical_limitations\": []\n",
    "            }\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricingStrategySpecialist(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Pricing analysis expert\"\n",
    "        self.goal = \"Analyze and compare pricing models and strategies\"\n",
    "        self.backstory = \"Former pricing consultant in SaaS industry\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Analyze pricing strategies and models.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"competitor_name\": {\n",
    "                \"pricing_tiers\": [],\n",
    "                \"pricing_model\": \"\",\n",
    "                \"discount_strategies\": [],\n",
    "                \"pricing_positioning\": \"\"\n",
    "            }\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitiveStrategyAnalyst(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Strategic analyst specializing in competitive analysis\"\n",
    "        self.goal = \"Synthesize competitive intelligence into strategic insights\"\n",
    "        self.backstory = \"Strategy consultant from major consulting firms\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Synthesize all competitive data into strategic insights.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"market_patterns\": [],\n",
    "            \"competitive_advantages\": {},\n",
    "            \"market_gaps\": [],\n",
    "            \"strategic_recommendations\": [],\n",
    "            \"threat_assessment\": {}\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitiveIntelligenceReportSpecialist(BaseAgent):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.role = \"Report creation specialist\"\n",
    "        self.goal = \"Create clear, actionable reports from competitive analysis\"\n",
    "        self.backstory = \"Communications expert in data visualization\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        Create a comprehensive report from all analyses.\n",
    "        Return results in JSON format:\n",
    "        {\n",
    "            \"executive_summary\": \"\",\n",
    "            \"key_findings\": [],\n",
    "            \"detailed_analysis\": {},\n",
    "            \"recommendations\": [],\n",
    "            \"market_overview\": \"\",\n",
    "            \"appendix\": {}\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitiveAnalysisWorkflow:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.market_scout = MarketIntelligenceScout(config)\n",
    "        self.product_analyst = DigitalProductAnalyst(config)\n",
    "        self.marketing_decoder = MarketingMessageDecoder(config)\n",
    "        self.technical_comparator = TechnicalFeatureComparator(config)\n",
    "        self.pricing_specialist = PricingStrategySpecialist(config)\n",
    "        self.competitive_analyst = CompetitiveStrategyAnalyst(config)\n",
    "        self.report_specialist = CompetitiveIntelligenceReportSpecialist(config)\n",
    "\n",
    "    async def run_parallel_analysis(self, competitors_data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Run parallel analysis tasks\"\"\"\n",
    "        tasks = [\n",
    "            self.product_analyst.execute(competitors_data),\n",
    "            self.marketing_decoder.execute(competitors_data),\n",
    "            self.technical_comparator.execute(competitors_data),\n",
    "            self.pricing_specialist.execute(competitors_data)\n",
    "        ]\n",
    "        \n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        return {\n",
    "            \"product_analysis\": results[0],\n",
    "            \"marketing_analysis\": results[1],\n",
    "            \"technical_analysis\": results[2],\n",
    "            \"pricing_analysis\": results[3]\n",
    "        }\n",
    "\n",
    "    async def execute_workflow(self, market_segment: str) -> Dict:\n",
    "        try:\n",
    "            logger.info(f\"Starting competitive analysis for {market_segment}\")\n",
    "            \n",
    "            # Step 1: Identify competitors\n",
    "            competitors_data = await self.market_scout.execute({\"market_segment\": market_segment})\n",
    "            logger.info(\"Completed competitor identification\")\n",
    "\n",
    "            # Step 2: Run parallel analysis\n",
    "            parallel_results = await self.run_parallel_analysis(competitors_data)\n",
    "            logger.info(\"Completed parallel analysis\")\n",
    "\n",
    "            # Step 3: Strategic analysis\n",
    "            strategic_analysis = await self.competitive_analyst.execute({\n",
    "                \"competitors_data\": competitors_data,\n",
    "                \"parallel_results\": parallel_results\n",
    "            })\n",
    "            logger.info(\"Completed strategic analysis\")\n",
    "\n",
    "            # Step 4: Generate report\n",
    "            final_report = await self.report_specialist.execute({\n",
    "                \"strategic_analysis\": strategic_analysis,\n",
    "                \"raw_data\": {\n",
    "                    \"competitors\": competitors_data,\n",
    "                    \"analysis\": parallel_results\n",
    "                }\n",
    "            })\n",
    "            logger.info(\"Completed final report generation\")\n",
    "\n",
    "            return final_report\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in workflow execution: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_workflow():\n",
    "    config = Config()\n",
    "    workflow = CompetitiveAnalysisWorkflow(config)\n",
    "    result = await workflow.execute_workflow(\"AI Development Platforms\")\n",
    "    print(\"\\nFinal Result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting competitive analysis for AI Development Platforms\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:__main__:Completed competitor identification\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:__main__:Completed parallel analysis\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:__main__:Completed strategic analysis\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:__main__:Completed final report generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Result:\n",
      "\"```json\\n{\\n    \\\"executive_summary\\\": \\\"The competitive landscape for AI development platforms is dominated by major cloud providers (Google, Amazon, Microsoft), each offering comprehensive, integrated solutions. These platforms leverage their existing ecosystems to provide scalable infrastructure, pre-built algorithms, and AutoML capabilities. Open-source libraries like TensorFlow and PyTorch are highly influential, forming the foundation for much of the AI development. End-to-end platforms such as Dataiku and RapidMiner focus on user-friendliness and collaboration, catering to less technical users. The market shows gaps in addressing explainable AI, industry-specific tools, and ease of use for non-technical users. A key strategic need is to balance ease of use with customizability, bridging the gap between open-source flexibility and enterprise-grade manageability.\\\",\\n    \\\"key_findings\\\": [\\n        \\\"Cloud-based platforms from Google, Amazon, and Microsoft are leading the market with broad feature sets and strong ecosystems.\\\",\\n        \\\"AutoML is a standard feature, reflecting the democratization of AI development.\\\",\\n        \\\"Open-source libraries are foundational and have high influence.\\\",\\n        \\\"There's a market gap for platforms that bridge open-source flexibility and enterprise manageability.\\\",\\n         \\\"Explainable AI and model interpretability are areas needing improvement.\\\",\\n        \\\"Industry specific AI tools and integration are in demand.\\\",\\n        \\\"User-friendly platforms for non-technical users are essential for broader adoption.\\\"\\n    ],\\n    \\\"detailed_analysis\\\": {\\n        \\\"market_overview\\\": {\\n          \\\"market_patterns\\\": [\\n              \\\"The market is dominated by cloud-based AI development platforms from major tech companies (Google, Amazon, Microsoft).\\\",\\n              \\\"There's a clear segmentation between end-to-end platforms (Dataiku), open-source libraries (TensorFlow, PyTorch), and more business-oriented platforms (RapidMiner).\\\",\\n               \\\"AutoML capabilities are becoming a standard feature across many platforms, indicating a push towards democratizing AI development.\\\",\\n               \\\"Integration with existing cloud ecosystems is a key differentiator for the major cloud providers.\\\",\\n               \\\"Open-source tools are highly relevant, influencing both research and practice in the domain.\\\"\\n          ],\\n          \\\"competitive_advantages\\\":{\\n              \\\"Google Cloud AI Platform\\\": \\\"Strong integration within the Google ecosystem, advanced TPU support, and mature AutoML capabilities.\\\",\\n              \\\"Amazon SageMaker\\\": \\\"Broad range of pre-built algorithms, a comprehensive ecosystem, and strong community support.\\\",\\n              \\\"Microsoft Azure Machine Learning\\\": \\\"Deep integration with the Microsoft ecosystem, hybrid deployment options, and a user-friendly visual interface (Azure ML Studio).\\\",\\n              \\\"IBM Watson Studio\\\": \\\"Focus on enterprise-grade AI solutions, strength in natural language processing, and enterprise focus.\\\",\\n              \\\"Dataiku\\\": \\\"End-to-end workflow focus, strong collaboration features, and accessibility for non-technical users.\\\",\\n              \\\"H2O.ai\\\": \\\"Strong AutoML capabilities, high performance for tabular data, and flexible, adaptable open-source structure.\\\",\\n              \\\"RapidMiner\\\": \\\"User-friendly visual interface, strong focus on business users, and all-in-one data science platform.\\\",\\n               \\\"TensorFlow\\\": \\\"Flexibility and customizability, large community, and strong focus on deep learning applications.\\\",\\n               \\\"PyTorch\\\": \\\"Ease of use, dynamic computational graph, and strong focus on research and flexibility.\\\"\\n          },\\n          \\\"market_gaps\\\":[\\n             \\\"A unified platform that bridges the gap between open-source flexibility and enterprise-grade manageability.\\\",\\n             \\\"A stronger focus on explainable AI and model interpretability within cloud-based solutions.\\\",\\n              \\\"Better tools and integration for specific industries' AI use cases.\\\",\\n              \\\"More accessible and intuitive platforms for truly non-technical users who want to leverage AI without significant coding knowledge.\\\",\\n               \\\"Improved solutions for addressing model deployment complexity and cost.\\\"\\n            ],\\n             \\\"threat_assessment\\\": {\\n                \\\"High\\\": [\\n                    \\\"Google Cloud AI Platform\\\",\\n                    \\\"Amazon SageMaker\\\",\\n                    \\\"Microsoft Azure Machine Learning\\\"\\n                ],\\n                \\\"Medium\\\": [\\n                     \\\"IBM Watson Studio\\\",\\n                    \\\"Dataiku\\\",\\n                    \\\"H2O.ai\\\",\\n                    \\\"RapidMiner\\\",\\n                    \\\"TensorFlow\\\",\\n                    \\\"PyTorch\\\"\\n                ],\\n                 \\\"analysis\\\": \\\"The major cloud providers present the highest threat due to their broad range of offerings, significant infrastructure capabilities, and strong market presence.  While other competitors are still highly relevant, they are often more niche or cater to specific types of users. The open source libraries are extremely influential but not in direct competition as they are used by most competitors.\\\"\\n            }\\n        },\\n        \\\"competitor_analysis\\\": {\\n            \\\"product_analysis\\\": {\\n                \\\"Google Cloud AI Platform\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Managed notebooks (JupyterLab)\\\",\\n                        \\\"Training and prediction services\\\",\\n                        \\\"Model deployment and management\\\",\\n                        \\\"AutoML for automated model building\\\",\\n                         \\\"Integration with other Google Cloud services (BigQuery, Dataflow)\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"Strong integration with Google's ecosystem\\\",\\n                        \\\"TPU support for accelerated training\\\",\\n                        \\\"AutoML capabilities\\\"\\n                    ],\\n                     \\\"user_experience\\\": \\\"Geared towards developers and data scientists comfortable with Google Cloud. Offers a mix of managed and configurable options.\\\",\\n                    \\\"product_maturity\\\": \\\"Mature platform with a wide range of features and a large user base.\\\"\\n                },\\n                \\\"Amazon SageMaker\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Managed notebooks (Jupyter)\\\",\\n                        \\\"Training and prediction services\\\",\\n                        \\\"Model deployment options\\\",\\n                        \\\"AutoML (SageMaker Autopilot)\\\",\\n                        \\\"Pre-built algorithms and models\\\",\\n                        \\\"Marketplace for algorithms and models\\\"\\n                    ],\\n                     \\\"unique_capabilities\\\": [\\n                         \\\"Wide selection of pre-built algorithms and models\\\",\\n                         \\\"Integration with other AWS services\\\",\\n                         \\\"Comprehensive ecosystem\\\",\\n                          \\\"Strong community support\\\"\\n                     ],\\n                    \\\"user_experience\\\":\\\"Offers a wide variety of services but can be complex. Good for developers and data scientists on AWS ecosystem.\\\",\\n                    \\\"product_maturity\\\": \\\"Mature platform with a wide range of features and a large user base.\\\"\\n                },\\n                \\\"Microsoft Azure Machine Learning\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Managed notebooks\\\",\\n                        \\\"Automated machine learning (AutoML)\\\",\\n                        \\\"Designer (visual interface for model building)\\\",\\n                        \\\"Training and deployment options\\\",\\n                        \\\"Integration with Azure services\\\",\\n                         \\\"Support for various frameworks (TensorFlow, PyTorch)\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"Integration with the broader Azure ecosystem\\\",\\n                        \\\"Strong focus on enterprise solutions\\\",\\n                         \\\"Hybrid deployment options\\\"\\n                    ],\\n                    \\\"user_experience\\\": \\\"Offers both coding and no-code options. Good for teams with diverse skill sets.\\\",\\n                    \\\"product_maturity\\\": \\\"Mature and rapidly evolving platform.\\\"\\n                },\\n                \\\"IBM Watson Studio\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Notebooks (Jupyter, RStudio)\\\",\\n                        \\\"Data visualization and preparation\\\",\\n                        \\\"AutoAI for automated model building\\\",\\n                        \\\"Model deployment and management\\\",\\n                        \\\"Integration with IBM Cloud services\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"Focus on enterprise-grade AI solutions\\\",\\n                       \\\"Strong capabilities in natural language processing\\\"\\n                    ],\\n                    \\\"user_experience\\\": \\\"Designed for both data scientists and business users. Offers a collaborative environment.\\\",\\n                    \\\"product_maturity\\\": \\\"Mature platform with a focus on enterprise use cases.\\\"\\n                },\\n                 \\\"Dataiku\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Visual interface for data preparation and model building\\\",\\n                        \\\"Collaboration features\\\",\\n                        \\\"Model deployment and monitoring\\\",\\n                        \\\"Support for various data sources\\\",\\n                        \\\"Automation of AI workflows\\\"\\n                    ],\\n                      \\\"unique_capabilities\\\": [\\n                        \\\"Focus on end-to-end AI workflows\\\",\\n                         \\\"Strong collaborative features\\\",\\n                         \\\"Ease of use for non-technical users\\\"\\n                    ],\\n                    \\\"user_experience\\\": \\\"Intuitive interface suitable for both technical and non-technical users.\\\",\\n                     \\\"product_maturity\\\": \\\"Mature platform, gaining popularity for end-to-end AI solutions.\\\"\\n                },\\n                \\\"H2O.ai\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Open-source machine learning platform\\\",\\n                        \\\"AutoML capabilities (H2O Driverless AI)\\\",\\n                        \\\"Support for various algorithms and frameworks\\\",\\n                        \\\"Scalable distributed training\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"Strong focus on AutoML\\\",\\n                         \\\"Enterprise-grade solutions\\\",\\n                         \\\"Flexibility and adaptability\\\"\\n                    ],\\n                     \\\"user_experience\\\":\\\"Designed for data scientists and researchers. Requires technical expertise\\\",\\n                    \\\"product_maturity\\\":\\\"Established platform with advanced AI capabilities.\\\"\\n                },\\n                \\\"RapidMiner\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Visual workflow designer\\\",\\n                        \\\"Data mining and machine learning tools\\\",\\n                        \\\"Model deployment and management\\\",\\n                        \\\"Support for various data sources\\\",\\n                        \\\"Pre-built templates and algorithms\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"User-friendly visual interface\\\",\\n                         \\\"Focus on business users\\\",\\n                         \\\"Wide range of data connectors\\\"\\n                    ],\\n                    \\\"user_experience\\\": \\\"Primarily designed for business users with less coding required.\\\",\\n                     \\\"product_maturity\\\": \\\"Established platform with a long history in data science.\\\"\\n                },\\n                \\\"TensorFlow\\\": {\\n                    \\\"key_features\\\": [\\n                        \\\"Open-source machine learning library\\\",\\n                        \\\"Support for deep learning and neural networks\\\",\\n                        \\\"Extensive documentation and community\\\",\\n                         \\\"Deployment on various platforms\\\"\\n                    ],\\n                    \\\"unique_capabilities\\\": [\\n                        \\\"Highly flexible and customizable\\\",\\n                        \\\"Large community support and ecosystem\\\",\\n                        \\\"Strong for deep learning applications\\\"\\n                    ],\\n                    \\\"user_experience\\\": \\\"Designed for developers and researchers with a good understanding of AI and coding.\\\",\\n                     \\\"product_maturity\\\": \\\"Mature and widely used open-source library.\\\"\\n                },\\n                 \\\"PyTorch\\\": {\\n                    \\\"key_features\\\": [\\n                       \\\"Open-source machine learning library\\\",\\n                       \\\"Dynamic computational graph\\\",\\n                       \\\"Support for deep learning and neural networks\\\",\\n                       \\\"Strong community and research focus\\\",\\n                       \\\"Flexible and easy to use\\\"\\n                    ],\\n                     \\\"unique_capabilities\\\": [\\n                        \\\"Research-oriented library\\\",\\n                        \\\"Flexible and dynamic framework\\\",\\n                        \\\"Strong GPU support\\\"\\n                     ],\\n                      \\\"user_experience\\\": \\\"Designed for researchers and developers with some coding skills.\\\",\\n                    \\\"product_maturity\\\": \\\"Rapidly growing open-source library with strong research community.\\\"\\n                }\\n            },\\n            \\\"marketing_analysis\\\": {\\n                 \\\"Google Cloud AI Platform\\\": {\\n                        \\\"value_propositions\\\": [\\n                            \\\"Scalable infrastructure for AI development\\\",\\n                            \\\"Integration with other Google Cloud services\\\",\\n                             \\\"Managed platform for machine learning workflows\\\",\\n                            \\\"Access to pre-trained models and APIs\\\",\\n                             \\\"Collaboration tools for data science teams\\\"\\n                        ],\\n                        \\\"messaging_tone\\\": \\\"Professional, Innovative, Cutting-edge\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, machine learning engineers, AI developers\\\",\\n                        \\\"unique_selling_points\\\": [\\n                             \\\"Tight integration with Google ecosystem\\\",\\n                             \\\"Strong focus on scale and performance\\\",\\n                             \\\"Access to Google's AI research and innovation\\\"\\n                        ]\\n                    },\\n                    \\\"Amazon SageMaker\\\": {\\n                        \\\"value_propositions\\\": [\\n                            \\\"End-to-end machine learning platform\\\",\\n                             \\\"Support for various machine learning algorithms and frameworks\\\",\\n                            \\\"Scalable and secure environment\\\",\\n                            \\\"Managed services for model building, training and deployment\\\",\\n                            \\\"Integration with other AWS services\\\"\\n                         ],\\n                        \\\"messaging_tone\\\": \\\"Comprehensive, Enterprise-grade, Reliable\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, machine learning engineers, enterprise clients\\\",\\n                        \\\"unique_selling_points\\\": [\\n                             \\\"Broad range of features and services\\\",\\n                             \\\"Integration with vast AWS infrastructure\\\",\\n                             \\\"Mature and well-established platform\\\"\\n                        ]\\n                    },\\n                    \\\"Microsoft Azure Machine Learning\\\": {\\n                        \\\"value_propositions\\\": [\\n                            \\\"Cloud-based machine learning platform\\\",\\n                            \\\"Support for open-source frameworks and languages\\\",\\n                            \\\"Collaborative environment for data science teams\\\",\\n                            \\\"Automated machine learning capabilities\\\",\\n                            \\\"Integration with other Azure services\\\"\\n                        ],\\n                        \\\"messaging_tone\\\": \\\"Modern, Collaborative, Accessible\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, machine learning engineers, AI developers familiar with Microsoft ecosystem\\\",\\n                        \\\"unique_selling_points\\\": [\\n                             \\\"Strong integration with Microsoft ecosystem\\\",\\n                            \\\"Focus on ease-of-use and collaboration\\\",\\n                            \\\"Hybrid deployment capabilities\\\"\\n                        ]\\n                    },\\n                     \\\"IBM Watson Studio\\\": {\\n                        \\\"value_propositions\\\": [\\n                            \\\"AI platform for building and deploying models\\\",\\n                            \\\"Support for various data science tools and languages\\\",\\n                            \\\"Collaborative environment for data science teams\\\",\\n                            \\\"Integration with IBM Watson AI services\\\",\\n                            \\\"Focus on enterprise solutions\\\"\\n                         ],\\n                        \\\"messaging_tone\\\": \\\"Expert, Enterprise-focused, Trusted\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, business analysts, enterprise clients\\\",\\n                         \\\"unique_selling_points\\\": [\\n                            \\\"Integration with IBM's AI and data management offerings\\\",\\n                             \\\"Strong focus on enterprise AI needs\\\",\\n                             \\\"Mature and established platform\\\"\\n                         ]\\n                    },\\n                     \\\"Dataiku\\\": {\\n                        \\\"value_propositions\\\": [\\n                             \\\"End-to-end platform for data science and machine learning\\\",\\n                            \\\"User-friendly interface for both technical and non-technical users\\\",\\n                             \\\"Collaborative environment for data teams\\\",\\n                             \\\"Support for various data sources and machine learning frameworks\\\",\\n                             \\\"Focus on accelerating AI projects\\\"\\n                        ],\\n                        \\\"messaging_tone\\\": \\\"User-friendly, Collaborative, Pragmatic\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, business analysts, citizen data scientists\\\",\\n                        \\\"unique_selling_points\\\": [\\n                             \\\"Focus on ease of use and accessibility\\\",\\n                             \\\"Collaborative features for teams\\\",\\n                             \\\"Strong capabilities for both data preparation and model deployment\\\"\\n                        ]\\n                    },\\n                     \\\"H2O.ai\\\": {\\n                        \\\"value_propositions\\\": [\\n                             \\\"Open-source machine learning platform\\\",\\n                            \\\"Scalable and high-performance algorithms\\\",\\n                            \\\"Automated machine learning capabilities\\\",\\n                             \\\"Support for various programming languages and frameworks\\\",\\n                            \\\"Focus on democratization of AI\\\"\\n                        ],\\n                        \\\"messaging_tone\\\": \\\"Open, Powerful, Flexible\\\",\\n                        \\\"target_audience\\\": \\\"Data scientists, machine learning engineers, AI researchers\\\",\\n                        \\\"unique_selling_points\\\": [\\n                             \\\"Open-source nature\\\",\\n                            \\\"Advanced automated machine learning capabilities\\\",\\n                             \\\"Strong performance for complex models\\\"\\n                        ]\\n                    },\\n                     \\\"RapidMiner\\\": {\\n                        \\\"value_propositions\\\": [\\n                           \\\"Data science platform with a visual workflow environment\\\",\\n                           \\\"Comprehensive toolkit for data preparation, machine learning, and predictive analytics\\\",\\n                           \\\"Supports a variety of data sources and machine learning algorithms\\\",\\n                           \\\"Focus on ease of use and rapid development\\\",\\n                           \\\"Offers both desktop and cloud versions\\\"\\n                        ],\\n                        \\\"messaging_tone\\\": \\\"Intuitive, Practical, Comprehensive\\\",\\n                         \\\"target_audience\\\":\\\"Data scientists, business analysts, data engineers\\\",\\n                        \\\"unique_selling_points\\\":[\\n                            \\\"Visual workflow designer for ease of use\\\",\\n                            \\\"All-in-one data science platform\\\",\\n                            \\\"Focus on accelerating model development\\\"\\n                        ]\\n                    },\\n                    \\\"TensorFlow\\\": {\\n                      \\\"value_propositions\\\": [\\n                        \\\"Open-source library for machine learning and deep learning\\\",\\n                        \\\"Flexible and extensible framework for building custom models\\\",\\n                        \\\"Large community support and resources\\\",\\n                        \\\"Support for various hardware platforms\\\",\\n                        \\\"Focus on research and development\\\"\\n                      ],\\n                      \\\"messaging_tone\\\": \\\"Innovative, Flexible, Community-driven\\\",\\n                      \\\"target_audience\\\": \\\"Machine learning researchers, AI developers, advanced users\\\",\\n                      \\\"unique_selling_points\\\": [\\n                           \\\"Flexibility and customizability for model development\\\",\\n                           \\\"Large and active community support\\\",\\n                           \\\"Strong focus on cutting-edge research\\\"\\n                      ]\\n                    },\\n                      \\\"PyTorch\\\": {\\n                      \\\"value_propositions\\\": [\\n                        \\\"Open-source machine learning library\\\",\\n                         \\\"Dynamic computational graph for flexible model building\\\",\\n                        \\\"Ease of use and beginner-friendliness\\\",\\n                         \\\"Strong community support and resources\\\",\\n                         \\\"Focus on research and experimentation\\\"\\n                      ],\\n                      \\\"messaging_tone\\\": \\\"Accessible, Flexible, Research-oriented\\\",\\n                      \\\"target_audience\\\": \\\"Machine learning researchers, AI developers, students\\\",\\n                      \\\"unique_selling_points\\\": [\\n                        \\\"Ease of use and intuitive API\\\",\\n                        \\\"Strong support for dynamic computation graphs\\\",\\n                         \\\"Growing community and ecosystem\\\"\\n                      ]\\n                    }\\n            },\\n            \\\"technical_analysis\\\": {\\n                \\\"Google Cloud AI Platform\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"TensorFlow\\\",\\n                            \\\"Keras\\\",\\n                            \\\"Scikit-learn\\\",\\n                            \\\"PyTorch\\\",\\n                            \\\"R\\\",\\n                             \\\"Containerization (Docker, Kubernetes)\\\",\\n                            \\\"Cloud Storage (Google Cloud Storage)\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                            \\\"REST API for model deployment and prediction\\\",\\n                            \\\"Client libraries for various programming languages\\\",\\n                            \\\"Pre-built AI APIs (Vision, Natural Language, Translation)\\\",\\n                            \\\"Vertex AI (unified platform)\\\",\\n                            \\\"AutoML capabilities\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                            \\\"Managed infrastructure scaling\\\",\\n                            \\\"Distributed training capabilities (TensorFlow, PyTorch)\\\",\\n                            \\\"Support for large datasets\\\",\\n                             \\\"Auto-scaling for model serving\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                             \\\"Tight integration with other Google Cloud services\\\",\\n                            \\\"Strong support for Kubernetes and containerization\\\",\\n                            \\\"Simplified model deployment through Vertex AI\\\",\\n                            \\\"Comprehensive set of pre-built AI models and APIs\\\",\\n                            \\\"AutoML features for faster model development\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                            \\\"Vendor lock-in with Google Cloud platform\\\",\\n                            \\\"Can be complex to set up for some users\\\",\\n                             \\\"Cost can be a factor\\\"\\n                        ]\\n                    },\\n                    \\\"Amazon SageMaker\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"TensorFlow\\\",\\n                            \\\"Keras\\\",\\n                            \\\"PyTorch\\\",\\n                            \\\"Scikit-learn\\\",\\n                            \\\"MXNet\\\",\\n                            \\\"R\\\",\\n                             \\\"Containerization (Docker)\\\",\\n                            \\\"Cloud Storage (S3)\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                            \\\"REST API for model deployment and prediction\\\",\\n                             \\\"Client libraries for various programming languages\\\",\\n                            \\\"Pre-built algorithms and models\\\",\\n                             \\\"AutoML capabilities (SageMaker Autopilot)\\\",\\n                             \\\"SageMaker Studio IDE\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                             \\\"Managed infrastructure scaling\\\",\\n                             \\\"Distributed training capabilities (TensorFlow, PyTorch, MXNet)\\\",\\n                             \\\"Support for large datasets\\\",\\n                              \\\"Auto-scaling for model serving\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                            \\\"Broad range of pre-built algorithms\\\",\\n                             \\\"Strong integration with other AWS services\\\",\\n                            \\\"SageMaker Studio provides a comprehensive IDE\\\",\\n                            \\\"Managed notebook instances for experimentation\\\",\\n                            \\\"Good support for various machine learning frameworks\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                            \\\"Vendor lock-in with AWS platform\\\",\\n                            \\\"Can be complex to configure various services\\\",\\n                            \\\"Cost can be a factor\\\"\\n                        ]\\n                    },\\n                    \\\"Microsoft Azure Machine Learning\\\": {\\n                         \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"TensorFlow\\\",\\n                            \\\"Keras\\\",\\n                            \\\"PyTorch\\\",\\n                            \\\"Scikit-learn\\\",\\n                            \\\"R\\\",\\n                             \\\"Containerization (Docker)\\\",\\n                            \\\"Cloud Storage (Azure Blob Storage)\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                           \\\"REST API for model deployment and prediction\\\",\\n                            \\\"Client libraries for various programming languages\\\",\\n                            \\\"Pre-built AI APIs (Cognitive Services)\\\",\\n                             \\\"AutoML capabilities\\\",\\n                             \\\"Azure Machine Learning Studio IDE\\\"\\n                         ],\\n                        \\\"scalability_features\\\": [\\n                             \\\"Managed infrastructure scaling\\\",\\n                             \\\"Distributed training capabilities (TensorFlow, PyTorch)\\\",\\n                            \\\"Support for large datasets\\\",\\n                            \\\"Auto-scaling for model serving\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                             \\\"Tight integration with other Azure services\\\",\\n                             \\\"Strong integration with Microsoft ecosystem (e.g., Power BI)\\\",\\n                              \\\"Comprehensive set of pre-built AI APIs (Cognitive Services)\\\",\\n                             \\\"User-friendly interface (Azure ML Studio)\\\",\\n                            \\\"Good support for enterprise customers\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                            \\\"Vendor lock-in with Azure platform\\\",\\n                            \\\"Some users find the platform complex to navigate\\\",\\n                            \\\"Cost can be a factor\\\"\\n                        ]\\n                    },\\n                    \\\"IBM Watson Studio\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"R\\\",\\n                            \\\"Scala\\\",\\n                            \\\"Spark\\\",\\n                            \\\"Jupyter Notebooks\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                             \\\"REST API for model deployment and prediction\\\",\\n                             \\\"Client libraries for various programming languages\\\",\\n                             \\\"Watson APIs (Vision, NLP, etc.)\\\",\\n                            \\\"AutoAI capabilities\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                            \\\"Support for Spark for large-scale data processing\\\",\\n                            \\\"Managed deployment infrastructure\\\"\\n                        ],\\n                       \\\"technical_advantages\\\": [\\n                            \\\"Strong focus on enterprise AI\\\",\\n                            \\\"Integration with IBM's other offerings\\\",\\n                            \\\"AutoAI features for automated model building\\\",\\n                            \\\"User-friendly collaborative environment\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                            \\\"Can be less flexible than some other platforms\\\",\\n                            \\\"Smaller community compared to AWS, Google, Azure\\\",\\n                            \\\"Potentially higher cost for enterprise features\\\"\\n                        ]\\n                    },\\n                    \\\"Dataiku\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"R\\\",\\n                            \\\"SQL\\\",\\n                            \\\"Spark\\\",\\n                            \\\"Hadoop\\\",\\n                            \\\"Various machine learning libraries\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                           \\\"REST API for model deployment and prediction\\\",\\n                           \\\"API for data integration\\\",\\n                           \\\"Plugin system for extending functionalities\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                            \\\"Support for large datasets with Spark and Hadoop\\\",\\n                            \\\"Horizontal scalability\\\",\\n                             \\\"Support for on-premise and cloud deployments\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                            \\\"Strong focus on collaboration and data lineage\\\",\\n                            \\\"Visual interface for data processing and model building\\\",\\n                            \\\"End-to-end data science platform\\\",\\n                            \\\"Supports hybrid deployment\\\"\\n                        ],\\n                       \\\"technical_limitations\\\": [\\n                            \\\"Can be expensive for small teams\\\",\\n                            \\\"Less flexibility compared to lower-level tools\\\",\\n                            \\\"Steeper learning curve for some users\\\"\\n                        ]\\n                    },\\n                    \\\"H2O.ai\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Java\\\",\\n                            \\\"Python\\\",\\n                            \\\"R\\\",\\n                             \\\"Distributed algorithms\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                             \\\"REST API for model deployment and prediction\\\",\\n                            \\\"Client libraries for various programming languages\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                            \\\"In-memory distributed processing\\\",\\n                             \\\"Support for large datasets\\\",\\n                            \\\"Scalable algorithms\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                            \\\"Focus on speed and performance\\\",\\n                            \\\"AutoML capabilities (Driverless AI)\\\",\\n                            \\\"Open source core with enterprise features\\\",\\n                            \\\"Strong capabilities for tabular data\\\"\\n                        ],\\n                         \\\"technical_limitations\\\": [\\n                            \\\"Limited support for deep learning tasks compared to frameworks like Tensorflow, PyTorch\\\",\\n                            \\\"Steeper learning curve for advanced features\\\",\\n                             \\\"Enterprise features require paid version\\\"\\n                        ]\\n                    },\\n                    \\\"RapidMiner\\\": {\\n                        \\\"tech_stack\\\": [\\n                             \\\"Java\\\",\\n                             \\\"GUI-based with scripting capabilities\\\",\\n                             \\\"Various machine learning libraries\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                            \\\"REST API for model deployment and prediction\\\",\\n                            \\\"Client libraries for various programming languages\\\",\\n                            \\\"Integration with other platforms\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                           \\\"Support for large datasets through streaming\\\",\\n                            \\\"Parallel processing\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                           \\\"Visual workflow design interface\\\",\\n                           \\\"Ease of use for non-programmers\\\",\\n                           \\\"Good for data exploration and prototyping\\\",\\n                            \\\"Integration with various data sources\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                            \\\"Less flexible for custom model development\\\",\\n                             \\\"Can be less efficient for advanced users\\\",\\n                            \\\"Not as scalable as some other options\\\"\\n                        ]\\n                    },\\n                    \\\"TensorFlow\\\": {\\n                         \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                             \\\"C++ (underlying implementation)\\\",\\n                            \\\"CUDA for GPU support\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                            \\\"Python API\\\",\\n                            \\\"C++ API (lower-level control)\\\",\\n                           \\\"TensorFlow Serving for model deployment\\\",\\n                             \\\"TensorFlow Lite for mobile and edge devices\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                           \\\"Distributed training support\\\",\\n                           \\\"GPU and TPU acceleration\\\",\\n                           \\\"Scalable across multiple devices\\\"\\n                        ],\\n                        \\\"technical_advantages\\\": [\\n                             \\\"Large and active community\\\",\\n                            \\\"Strong support for deep learning tasks\\\",\\n                             \\\"Flexible and powerful for custom model building\\\",\\n                           \\\"Good for research and complex AI models\\\"\\n                        ],\\n                       \\\"technical_limitations\\\": [\\n                            \\\"Steeper learning curve for beginners\\\",\\n                           \\\"Can be complex to set up for production deployments\\\",\\n                           \\\"Lower-level API can be verbose\\\"\\n                        ]\\n                    },\\n                    \\\"PyTorch\\\": {\\n                        \\\"tech_stack\\\": [\\n                            \\\"Python\\\",\\n                            \\\"C++ (underlying implementation)\\\",\\n                            \\\"CUDA for GPU support\\\"\\n                        ],\\n                        \\\"api_capabilities\\\": [\\n                            \\\"Python API\\\",\\n                           \\\"C++ API (for production)\\\",\\n                             \\\"TorchServe for model deployment\\\",\\n                            \\\"TorchMobile for mobile and edge devices\\\"\\n                        ],\\n                        \\\"scalability_features\\\": [\\n                            \\\"Distributed training support\\\",\\n                           \\\"GPU and TPU acceleration\\\",\\n                            \\\"Scalable across multiple devices\\\"\\n                        ],\\n                       \\\"technical_advantages\\\": [\\n                            \\\"Dynamic computation graph for flexibility\\\",\\n                           \\\"Easy to use and intuitive Python API\\\",\\n                            \\\"Strong community\\\",\\n                            \\\"Strong for research and complex AI models\\\"\\n                        ],\\n                        \\\"technical_limitations\\\": [\\n                             \\\"Can be less mature in some areas compared to TensorFlow\\\",\\n                             \\\"Steeper learning curve for C++ API usage\\\",\\n                             \\\"Can be less optimized for large scale production environments than TensorFlow\\\"\\n                        ]\\n                    }\\n            },\\n            \\\"pricing_analysis\\\": {\\n                \\\"Google Cloud AI Platform\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Pay-as-you-go\\\",\\n                             \\\"Custom pricing for large workloads\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Consumption-based\\\",\\n                        \\\"discount_strategies\\\": [\\n                             \\\"Sustained use discounts\\\",\\n                             \\\"Committed use discounts\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"Scalable and cost-effective for diverse AI workloads, with discounts for committed usage.\\\"\\n                    },\\n                    \\\"Amazon SageMaker\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Pay-as-you-go\\\",\\n                            \\\"Reserved instance pricing\\\",\\n                            \\\"Savings Plans\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Consumption-based\\\",\\n                        \\\"discount_strategies\\\": [\\n                           \\\"Reserved Instance discounts\\\",\\n                           \\\"Savings Plans discounts\\\",\\n                            \\\"Volume discounts\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"Comprehensive AI platform with flexible pricing options to optimize costs for different needs.\\\"\\n                    },\\n                    \\\"Microsoft Azure Machine Learning\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                             \\\"Pay-as-you-go\\\",\\n                              \\\"Reserved capacity pricing\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Consumption-based\\\",\\n                        \\\"discount_strategies\\\": [\\n                             \\\"Azure Hybrid Benefit\\\",\\n                             \\\"Reserved capacity discounts\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"Integrated AI platform within the Azure ecosystem, offering cost benefits for existing Azure users.\\\"\\n                    },\\n                    \\\"IBM Watson Studio\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Lite (free)\\\",\\n                            \\\"Professional\\\",\\n                            \\\"Enterprise\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Tiered subscription with pay-as-you-go options\\\",\\n                        \\\"discount_strategies\\\": [\\n                            \\\"Volume discounts for enterprise plans\\\",\\n                            \\\"Custom pricing for specific needs\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"Enterprise-focused platform with tiered pricing options, suitable for both individual data scientists and large teams.\\\"\\n                    },\\n                     \\\"Dataiku\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Free Trial\\\",\\n                            \\\"Team\\\",\\n                             \\\"Business\\\",\\n                             \\\"Enterprise\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Tiered subscription based on platform access and number of users\\\",\\n                          \\\"discount_strategies\\\": [\\n                            \\\"Custom pricing and volume discounts for large deployments\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"End-to-end collaborative platform, priced according to usage and features, targeting a range of organization sizes.\\\"\\n                    },\\n                      \\\"H2O.ai\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Free open-source core\\\",\\n                            \\\"Enterprise license\\\",\\n                             \\\"Cloud service tiers\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Open-source core with tiered enterprise licensing and cloud consumption pricing\\\",\\n                         \\\"discount_strategies\\\": [\\n                            \\\"Custom enterprise pricing based on specific usage\\\",\\n                           \\\"Potential bulk discounts\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"Open-source platform with commercial licensing, aiming to address both community and enterprise user base.\\\"\\n                    },\\n                    \\\"RapidMiner\\\": {\\n                         \\\"pricing_tiers\\\": [\\n                            \\\"Free tier\\\",\\n                            \\\"Professional\\\",\\n                            \\\"Enterprise\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Subscription-based, tiered access with optional add-ons\\\",\\n                        \\\"discount_strategies\\\": [\\n                           \\\"Potential volume discounts for enterprise users\\\",\\n                           \\\"Academic pricing\\\"\\n                        ],\\n                        \\\"pricing_positioning\\\": \\\"User-friendly data science platform, with pricing ranging from individual user to large enterprises\\\"\\n                    },\\n                    \\\"TensorFlow\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Free\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Open-source\\\",\\n                         \\\"discount_strategies\\\": [],\\n                        \\\"pricing_positioning\\\": \\\"Free open-source machine learning library, no direct costs, but development and infrastructure costs for deployment\\\"\\n                    },\\n                    \\\"PyTorch\\\": {\\n                        \\\"pricing_tiers\\\": [\\n                            \\\"Free\\\"\\n                        ],\\n                        \\\"pricing_model\\\": \\\"Open-source\\\",\\n                        \\\"discount_strategies\\\": [],\\n                        \\\"pricing_positioning\\\": \\\"Free open-source machine learning framework, no licensing costs but infrastructure costs required for running models\\\"\\n                    }\\n            }\\n        }\\n    },\\n    \\\"recommendations\\\": [\\n        \\\"Cloud platform providers should invest in industry-specific use cases and improve ease of use for non-technical users.\\\",\\n        \\\"Open-source solutions should improve tooling for model deployment and scaling in production.\\\",\\n        \\\"End-to-end platforms should focus on specific niches and improve collaborative workflows.\\\",\\n        \\\"All platforms should prioritize explainable AI and model interpretability to build user trust.\\\",\\n         \\\"Balance ease-of-use and customizability for diverse user needs.\\\",\\n        \\\"Leverage the flexibility of open-source while building robust enterprise-ready products with integrated deployment, scalability and security.\\\",\\n        \\\"Transparent and flexible pricing models that address cost concerns.\\\"\\n    ],\\n    \\\"market_overview\\\": \\\"The market is dominated by major cloud providers offering end-to-end AI platforms. Open-source libraries are highly influential, while end-to-end platforms target a user-friendly experience. There's an opportunity to bridge open-source flexibility with enterprise manageability.\\\",\\n  \\\"appendix\\\": {\\n      \\\"competitors_list\\\": {\\n        \\\"competitors\\\": [\\n          {\\n              \\\"name\\\": \\\"Google Cloud AI Platform\\\",\\n              \\\"website\\\": \\\"https://cloud.google.com/ai-platform\\\",\\n              \\\"market_segment\\\": \\\"Cloud-based AI Development Platform\\\",\\n               \\\"threat_level\\\": \\\"High\\\"\\n            },\\n            {\\n              \\\"name\\\": \\\"Amazon SageMaker\\\",\\n              \\\"website\\\": \\\"https://aws.amazon.com/sagemaker/\\\",\\n               \\\"market_segment\\\": \\\"Cloud-based AI Development Platform\\\",\\n               \\\"threat_level\\\": \\\"High\\\"\\n             },\\n              {\\n                \\\"name\\\": \\\"Microsoft Azure Machine Learning\\\",\\n                \\\"website\\\": \\\"https://azure.microsoft.com/en-us/products/machine-learning\\\",\\n                \\\"market_segment\\\": \\\"Cloud-based AI Development Platform\\\",\\n                \\\"threat_level\\\": \\\"High\\\"\\n             },\\n             {\\n                \\\"name\\\": \\\"IBM Watson Studio\\\",\\n                \\\"website\\\": \\\"https://www.ibm.com/cloud/watson-studio\\\",\\n                \\\"market_segment\\\": \\\"Cloud-based AI Development Platform\\\",\\n                \\\"threat_level\\\": \\\"Medium\\\"\\n              },\\n              {\\n                \\\"name\\\": \\\"Dataiku\\\",\\n                \\\"website\\\": \\\"https://www.dataiku.com/\\\",\\n                 \\\"market_segment\\\": \\\"End-to-end AI Development Platform\\\",\\n                 \\\"threat_level\\\": \\\"Medium\\\"\\n             },\\n              {\\n                 \\\"name\\\": \\\"H2O.ai\\\",\\n                 \\\"website\\\": \\\"https://h2o.ai/\\\",\\n                  \\\"market_segment\\\": \\\"Open Source AI Development Platform\\\",\\n                  \\\"threat_level\\\": \\\"Medium\\\"\\n             },\\n              {\\n                 \\\"name\\\": \\\"RapidMiner\\\",\\n                 \\\"website\\\": \\\"https://rapidminer.com/\\\",\\n                  \\\"market_segment\\\": \\\"Data Science Platform\\\",\\n                  \\\"threat_level\\\":\\\"Medium\\\"\\n                },\\n                 {\\n                    \\\"name\\\": \\\"TensorFlow\\\",\\n                    \\\"website\\\": \\\"https://www.tensorflow.org/\\\",\\n                     \\\"market_segment\\\": \\\"Open-source AI Library\\\",\\n                    \\\"threat_level\\\":\\\"Medium\\\"\\n                 },\\n                 {\\n                     \\\"name\\\":\\\"PyTorch\\\",\\n                    \\\"website\\\":\\\"https://pytorch.org/\\\",\\n                    \\\"market_segment\\\":\\\"Open-source AI Library\\\",\\n                    \\\"threat_level\\\":\\\"Medium\\\"\\n                 }\\n        ]\\n      }\\n  }\\n}\\n```\\n\"\n"
     ]
    }
   ],
   "source": [
    "result = await test_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_to_markdown(json_str, output_file=\"output.md\"):\n",
    "    \"\"\"\n",
    "    Converts a JSON string to a Markdown formatted string and saves it to a file.\n",
    "    Handles incomplete JSON strings due to potential truncation.\n",
    "\n",
    "    Args:\n",
    "        json_str: A string containing potentially incomplete JSON data.\n",
    "        output_file: The name of the file to save the markdown output to. Defaults to \"output.md\".\n",
    "\n",
    "    Returns:\n",
    "        A string containing the Markdown representation of the JSON data, or an error message.\n",
    "        Also saves the markdown output to the specified file if successful.\n",
    "    \"\"\"\n",
    "    # Remove the ```json\\n and \\n from the string\n",
    "    json_str = json_str.replace(\"```json\\n\", \"\").strip()\n",
    "\n",
    "    # 1. Check for Incomplete JSON\n",
    "    if not json_str:\n",
    "        return \"Error: Empty JSON string provided.\"\n",
    "\n",
    "    # Basic check for closing brace or bracket\n",
    "    if not (json_str.endswith('}') or json_str.endswith(']')):\n",
    "        # More robust check using regex\n",
    "        if not re.search(r'(\\{|\\[)\\s*([^\\}\\]]*\\s*)*(\\}|\\])\\s*$', json_str):\n",
    "            # 2. Attempt to Repair the JSON\n",
    "            if json_str.count('{') > json_str.count('}'):\n",
    "                json_str += '}'\n",
    "            elif json_str.count('[') > json_str.count(']'):\n",
    "                json_str += ']'\n",
    "            else:\n",
    "                # Attempt to truncate to last valid structure\n",
    "                try:\n",
    "                    last_valid_index = max(json_str.rfind('{'), json_str.rfind('['))\n",
    "                    if last_valid_index != -1:\n",
    "                        json_str = json_str[:last_valid_index + 1]\n",
    "                        if not (json_str.endswith('}') or json_str.endswith(']')):\n",
    "                            return \"Error: Incomplete JSON string, could not repair.\"\n",
    "                    else:\n",
    "                        return \"Error: Incomplete JSON string, could not repair.\"\n",
    "                except:\n",
    "                    return \"Error: Incomplete JSON string, could not repair.\"\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"Error: Invalid JSON string after repair: {e}\"\n",
    "\n",
    "    markdown_output = \"\"\n",
    "\n",
    "    def process_item(key, value, level=0):\n",
    "        nonlocal markdown_output\n",
    "        indent = \"  \" * level\n",
    "        if isinstance(value, dict):\n",
    "            markdown_output += f\"{indent}**{key.replace('_', ' ').title()}:**\\n\"\n",
    "            for k, v in value.items():\n",
    "                process_item(k, v, level + 1)\n",
    "        elif isinstance(value, list):\n",
    "            markdown_output += f\"{indent}**{key.replace('_', ' ').title()}:**\\n\"\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    process_item(\"item\", item, level + 1)\n",
    "                else:\n",
    "                    markdown_output += f\"{indent}  - {item}\\n\"\n",
    "        else:\n",
    "            markdown_output += f\"{indent}**{key.replace('_', ' ').title()}:** {value}\\n\"\n",
    "\n",
    "    for key, value in data.items():\n",
    "        process_item(key, value)\n",
    "\n",
    "    # Save to file\n",
    "    try:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(markdown_output)\n",
    "        print(f\"Markdown output saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to file: {e}\")\n",
    "\n",
    "    return markdown_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_json_to_markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_json_to_markdown\u001b[49m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI Development Platforms Report.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_json_to_markdown' is not defined"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_json_to_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAI Development Platforms Report.md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m, in \u001b[0;36msave_json_to_markdown\u001b[0;34m(json_str, output_file)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Basic check for closing brace or bracket\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (json_str\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m json_str\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# More robust check using regex\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms*([^\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m]]*\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms*)*(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m}|\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m])\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms*$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# 2. Attempt to Repair the JSON\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m json_str\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m>\u001b[39m json_str\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     27\u001b[0m             json_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/agent/lib/python3.13/re/__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_json_to_markdown(result, \"AI Development Platforms Report.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
